{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "psutil.virtual_memory().available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/test_cnn_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('../data/data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('../data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(list(glob.glob(os.path.join(DATA_PATH, '*/*/*.png'))))\n",
    "\"total images: {}\".format(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(DATA_PATH,'train')\n",
    "val_dir = os.path.join(DATA_PATH,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(list(glob.glob(train_dir+'/*/*.png'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = np.array([item for item in os.listdir(train_dir)])\n",
    "\"classes: {}\".format(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:')\n",
    "for cls in CLASSES:\n",
    "    print(f\"number of images belonging to {cls} class: {len(os.listdir(os.path.join(train_dir,cls)))}\")\n",
    "    \n",
    "print('\\nValidation:')\n",
    "for cls in CLASSES:\n",
    "    print(f\"number of images belonging to {cls} class: {len(os.listdir(os.path.join(val_dir,cls)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataset(batch_size):\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    return train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_dataset(batch_size):\n",
    "    val_generator = test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(300, 300),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    return val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_cnn():\n",
    "    model = Sequential([\n",
    "#         layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
    "#         layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
    "#         layers.Conv2D(512, 3, padding='same', activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_worker_batch_size = 10\n",
    "train_generator = get_train_dataset(per_worker_batch_size)\n",
    "validation_generator = get_val_dataset(2)\n",
    "single_worker_model = build_and_compile_cnn()\n",
    "single_worker_model.fit(train_generator, validation_data=validation_generator, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CONFIG'] = json.dumps({\n",
    "    'cluster': {\n",
    "        'worker': [\"localhost:12345\", \"localhost:23456\"]\n",
    "    },\n",
    "    'task': {'type': 'worker', 'index': 0}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "per_worker_batch_size = 10\n",
    "\n",
    "# Here the batch size scales up by number of workers since \n",
    "# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, \n",
    "# and now this becomes 128.\n",
    "global_batch_size = per_worker_batch_size * num_workers\n",
    "train_generator = get_train_dataset(per_worker_batch_size)\n",
    "validation_generator = get_val_dataset(2)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Model building/compiling need to be within `strategy.scope()`.\n",
    "  multi_worker_model = build_and_compile_cnn()\n",
    "\n",
    "# Keras' `model.fit()` trains the model with specified number of epochs and\n",
    "# number of steps per epoch. Note that the numbers here are for demonstration\n",
    "# purposes only and may not sufficiently produce a model with good quality.\n",
    "multi_worker_model.fit(train_generator, validation_data=validation_generator, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-2-gpu.2-2.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
